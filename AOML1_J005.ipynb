{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9f3fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib  # For saving models and transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e43efcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diabetes.csv\")  # Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71ac6fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_bmi(bmi):\n",
    "    if bmi < 18.5:\n",
    "        return \"Underweight\"\n",
    "    elif 18.5 <= bmi < 24.9:\n",
    "        return \"Normal weight\"\n",
    "    elif 25 <= bmi < 29.9:\n",
    "        return \"Overweight\"\n",
    "    else:\n",
    "        return \"Obese\"\n",
    "\n",
    "df[\"BMI_category\"] = df[\"BMI\"].apply(categorize_bmi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ba94c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Outcome\"])  # Features\n",
    "y = df[\"Outcome\"]  # Target\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e5bf108",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"Age\"]\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "X_val[numeric_features] = scaler.transform(X_val[numeric_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b22c6eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "categorical_features = [\"BMI_category\"]\n",
    "encoder = OneHotEncoder(drop=\"first\", sparse=False)\n",
    "X_train_encoded = encoder.fit_transform(X_train[categorical_features])\n",
    "X_val_encoded = encoder.transform(X_val[categorical_features])\n",
    "\n",
    "# Convert encoded features into DataFrame\n",
    "encoded_train_df = pd.DataFrame(X_train_encoded, columns=encoder.get_feature_names_out(categorical_features))\n",
    "encoded_val_df = pd.DataFrame(X_val_encoded, columns=encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "# Drop original categorical column and add encoded columns\n",
    "X_train = X_train.drop(columns=categorical_features).reset_index(drop=True)\n",
    "X_val = X_val.drop(columns=categorical_features).reset_index(drop=True)\n",
    "\n",
    "X_train = pd.concat([X_train, encoded_train_df], axis=1)\n",
    "X_val = pd.concat([X_val, encoded_val_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53a5c604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN Model: k=7, F1 Score=0.5577\n"
     ]
    }
   ],
   "source": [
    "best_knn, best_k, best_knn_score = None, None, 0\n",
    "\n",
    "for k in [3, 5, 7]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    \n",
    "    if f1 > best_knn_score:\n",
    "        best_knn, best_k, best_knn_score = knn, k, f1\n",
    "\n",
    "print(f\"Best KNN Model: k={best_k}, F1 Score={best_knn_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4394f76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree: max_depth=5, F1 Score=0.7222\n"
     ]
    }
   ],
   "source": [
    "best_tree, best_depth, best_tree_score = None, None, 0\n",
    "\n",
    "for depth in [3, 5, 7]:\n",
    "    tree = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    tree.fit(X_train, y_train)\n",
    "    y_pred = tree.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    if f1 > best_tree_score:\n",
    "        best_tree, best_depth, best_tree_score = tree, depth, f1\n",
    "\n",
    "print(f\"Best Decision Tree: max_depth={best_depth}, F1 Score={best_tree_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f476443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model: tree_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Choose best model\n",
    "best_model = best_knn if best_knn_score > best_tree_score else best_tree\n",
    "model_name = \"knn_model.pkl\" if best_knn_score > best_tree_score else \"tree_model.pkl\"\n",
    "\n",
    "# Save model, scaler, and encoder\n",
    "joblib.dump(best_model, model_name)\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(encoder, \"encoder.pkl\")\n",
    "\n",
    "print(f\"Saved best model: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "706777c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample):\n",
    "    # Load preprocessor and model\n",
    "    preprocessor = joblib.load(\"preprocessor.pkl\")\n",
    "    model = joblib.load(\"best_model.pkl\")\n",
    "\n",
    "    # Convert sample to DataFrame\n",
    "    sample_df = pd.DataFrame([sample])\n",
    "\n",
    "    # **Recompute BMI Category**\n",
    "    sample_df[\"BMI_category\"] = sample_df[\"BMI\"].apply(categorize_bmi)\n",
    "\n",
    "    # Apply preprocessing\n",
    "    sample_transformed = preprocessor.transform(sample_df)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(sample_transformed)\n",
    "    return \"Diabetic\" if prediction[0] == 1 else \"Non-Diabetic\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8669b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample):\n",
    "    # Load saved model and transformers\n",
    "    model = joblib.load(\"best_model.pkl\")\n",
    "    scaler = joblib.load(\"scaler.pkl\")\n",
    "    encoder = joblib.load(\"encoder.pkl\")\n",
    "    trained_columns = joblib.load(\"trained_feature_columns.pkl\")  # Ensure feature consistency\n",
    "\n",
    "    # Convert sample to DataFrame\n",
    "    sample_df = pd.DataFrame([sample])\n",
    "\n",
    "    # Apply standard scaling on numeric features\n",
    "    sample_df[numeric_features] = scaler.transform(sample_df[numeric_features])\n",
    "\n",
    "    # Apply one-hot encoding\n",
    "    encoded_sample = encoder.transform(sample_df[categorical_features])\n",
    "    encoded_sample_df = pd.DataFrame(\n",
    "        encoded_sample, columns=encoder.get_feature_names_out(categorical_features)\n",
    "    )\n",
    "\n",
    "    # Drop original categorical columns and concatenate encoded features\n",
    "    sample_df = sample_df.drop(columns=categorical_features).reset_index(drop=True)\n",
    "    sample_df = pd.concat([sample_df, encoded_sample_df], axis=1)\n",
    "\n",
    "    # Ensure test data has the same feature set as training data\n",
    "    for col in trained_columns:\n",
    "        if col not in sample_df.columns:\n",
    "            sample_df[col] = 0  # Add missing columns with default value (0 for one-hot encoding)\n",
    "\n",
    "    # Ensure correct order and remove extra columns\n",
    "    sample_df = sample_df[trained_columns]\n",
    "\n",
    "    # Convert to NumPy array to remove feature names\n",
    "    sample_array = sample_df.to_numpy()\n",
    "\n",
    "    # Predict class\n",
    "    prediction = model.predict(sample_array)\n",
    "    return \"Diabetic\" if prediction[0] == 1 else \"Non-Diabetic\"\n",
    "\n",
    "# Save feature names during training (Ensure you do this when training the model)\n",
    "joblib.dump(X_train.columns.tolist(), \"trained_feature_columns.pkl\")\n",
    "\n",
    "# Test inference with 5 samples\n",
    "for i in range(5):\n",
    "    sample = X_val.iloc[i].to_dict()\n",
    "    print(f\"Sample {i+1}: {predict(sample)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9606361d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN model: k=5, F1 Score=0.588\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib  # For saving models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "\n",
    "def categorize_bmi(bmi):\n",
    "    if bmi < 18.5:\n",
    "        return \"Underweight\"\n",
    "    elif 18.5 <= bmi < 24.9:\n",
    "        return \"Normal\"\n",
    "    elif 25 <= bmi < 29.9:\n",
    "        return \"Overweight\"\n",
    "    else:\n",
    "        return \"Obese\"\n",
    "\n",
    "df[\"BMI_category\"] = df[\"BMI\"].apply(categorize_bmi)\n",
    "\n",
    "\n",
    "X = df.drop(columns=[\"Outcome\"])\n",
    "y = df[\"Outcome\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "num_features = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
    "cat_features = [\"BMI_category\"]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_features),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features)\n",
    "])\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "\n",
    "# Save the preprocessor for inference\n",
    "joblib.dump(preprocessor, \"preprocessor.pkl\")\n",
    "\n",
    "\n",
    "best_knn, best_k, best_f1_knn = None, None, 0\n",
    "for k in [3, 5, 7]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_transformed, y_train)\n",
    "    y_pred = knn.predict(X_val_transformed)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    if f1 > best_f1_knn:\n",
    "        best_knn, best_k, best_f1_knn = knn, k, f1\n",
    "\n",
    "print(f\"Best KNN model: k={best_k}, F1 Score={best_f1_knn:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "383e11aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree model: max_depth=5, F1 Score=0.704\n",
      "Sample 1: Diabetic\n",
      "Sample 2: Non-Diabetic\n",
      "Sample 3: Non-Diabetic\n",
      "Sample 4: Diabetic\n",
      "Sample 5: Non-Diabetic\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_dt, best_depth, best_f1_dt = None, None, 0\n",
    "for depth in [3, 5, 7]:\n",
    "    dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    dt.fit(X_train_transformed, y_train)\n",
    "    y_pred = dt.predict(X_val_transformed)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    if f1 > best_f1_dt:\n",
    "        best_dt, best_depth, best_f1_dt = dt, depth, f1\n",
    "\n",
    "print(f\"Best Decision Tree model: max_depth={best_depth}, F1 Score={best_f1_dt:.3f}\")\n",
    "\n",
    "best_model = best_knn if best_f1_knn > best_f1_dt else best_dt\n",
    "joblib.dump(best_model, \"best_model.pkl\")\n",
    "\n",
    "\n",
    "def predict(sample):\n",
    "    # Load preprocessor and model\n",
    "    preprocessor = joblib.load(\"preprocessor.pkl\")\n",
    "    model = joblib.load(\"best_model.pkl\")\n",
    "\n",
    "    # Convert sample to DataFrame & Apply preprocessing\n",
    "    sample_df = pd.DataFrame([sample])\n",
    "    sample_transformed = preprocessor.transform(sample_df)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(sample_transformed)\n",
    "    return \"Diabetic\" if prediction[0] == 1 else \"Non-Diabetic\"\n",
    "\n",
    "for i in range(5):\n",
    "    sample = X_val.iloc[i].to_dict()\n",
    "    print(f\"Sample {i+1}: {predict(sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb12e117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
